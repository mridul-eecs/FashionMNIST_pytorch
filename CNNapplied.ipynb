{"cells":[{"cell_type":"code","execution_count":1,"metadata":{},"outputs":[],"source":["%config IPCompleter.greedy=True"]},{"cell_type":"code","execution_count":2,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":"True\n0.4.1\n"}],"source":"import torch\nimport torchvision\nimport torch.nn as nn\nimport torch.optim as optim\nimport torchvision.transforms.transforms as transforms\nimport torch.nn.functional as func\n\nprint(torch.cuda.is_available())\nprint(torch.__version__)"},{"cell_type":"code","execution_count":3,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":"train set: 60000\ntest set: 10000\n"}],"source":"train_set= torchvision.datasets.FashionMNIST(\n    train= True,\n    root= './data/FashionMNIST/train/',\n    download= True,\n    transform= transforms.Compose([transforms.ToTensor()])\n)\ntest_set= torchvision.datasets.FashionMNIST(\n    train= False,\n    root= './data/FashionMNIST/test/',\n    download= True,\n    transform= transforms.Compose([transforms.ToTensor()])\n)\nprint(\"train set:\", len(train_set))\nprint(\"test set:\", len(test_set))"},{"cell_type":"code","execution_count":4,"metadata":{},"outputs":[],"source":"# Network\n# formula for channels \n\nclass Network(nn.Module):\n    def __init__(self):\n        super(Network, self).__init__()\n        # Convolutional layer1\n        self.conv1= nn.Sequential()\n        self.conv1.add_module(\"conv1\", nn.Conv2d(in_channels= 1, out_channels= 6, kernel_size= 5))\n        self.conv1.add_module(\"bn1\", nn.BatchNorm2d(num_features= 6, eps= 1e-05, momentum= 0.1, affine= True))\n        self.conv1.add_module(\"relu\", nn.ReLU(inplace= False))\n        self.conv1.add_module(\"pool\", nn.MaxPool2d(kernel_size= 2, stride= 2))\n\n        # Convolutional layer2\n        self.conv2= nn.Sequential()\n        self.conv2.add_module(\"conv2\", nn.Conv2d(in_channels= 6, out_channels= 12, kernel_size= 5))\n        self.conv2.add_module(\"bn2\", nn.BatchNorm2d(num_features= 12, eps= 1e-05, momentum= 0.1, affine= True))\n        self.conv2.add_module(\"relu\", nn.ReLU(inplace= False))\n        self.conv2.add_module(\"pool\", nn.MaxPool2d(kernel_size= 2, stride= 2))\n\n        # Linear layer1\n        self.fc1= nn.Sequential()\n        self.fc1.add_module(\"linear\", nn.Linear(in_features= 12*4*4, out_features= 120))\n        #  self.fc1.add_module(\"bn3\", nn.BatchNorm1d(num_features= 120, eps= 1e-05, momentum= 0.1, affine= True))\n        self.fc1.add_module(\"relu\", nn.ReLU(inplace= False))\n        \n        # Linear layer2\n        self.fc2= nn.Sequential()\n        self.fc2.add_module(\"linear\", nn.Linear(in_features= 120, out_features= 60))\n        #self.fc2.add_module(\"bn4\", nn.BatchNorm1d(num_features= 60, eps= 1e-5, momentum= 0.1, affine= True))\n        self.fc2.add_module(\"relu\", nn.ReLU(inplace= False))\n\n        # Output layer\n        self.out= nn.Sequential()\n        self.out.add_module(\"output\", nn.Linear(in_features= 60, out_features= 10))\n        # by default activation function is softmax\n\n    def forward(self, t):\n        t= t\n        t= self.conv1(t)\n        t= self.conv2(t)\n        t= t.reshape(-1, 12*4*4)\n        t= self.fc1(t)\n        t= self.fc2(t)\n        t= self.out(t)\n        return t"},{"cell_type":"code","execution_count":5,"metadata":{},"outputs":[{"data":{"text/plain":"Network(\n  (conv1): Sequential(\n    (conv1): Conv2d(1, 6, kernel_size=(5, 5), stride=(1, 1))\n    (bn1): BatchNorm2d(6, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    (relu): ReLU()\n    (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n  )\n  (conv2): Sequential(\n    (conv2): Conv2d(6, 12, kernel_size=(5, 5), stride=(1, 1))\n    (bn2): BatchNorm2d(12, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    (relu): ReLU()\n    (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n  )\n  (fc1): Sequential(\n    (linear): Linear(in_features=192, out_features=120, bias=True)\n    (relu): ReLU()\n  )\n  (fc2): Sequential(\n    (linear): Linear(in_features=120, out_features=60, bias=True)\n    (relu): ReLU()\n  )\n  (out): Sequential(\n    (output): Linear(in_features=60, out_features=10, bias=True)\n  )\n)"},"execution_count":5,"metadata":{},"output_type":"execute_result"}],"source":"# Instance of Network\nnetwork= Network()\nnetwork"},{"cell_type":"code","execution_count":6,"metadata":{},"outputs":[],"source":"train_loader= torch.utils.data.DataLoader(train_set, batch_size= 10)"},{"cell_type":"code","execution_count":7,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":"train_loss: 2.3143973350524902\ntest_loss: 2.3147315979003906\n"}],"source":"network= Network()\n\ntrain_loader= torch.utils.data.DataLoader(train_set, batch_size= 1000)\ntest_loader= torch.utils.data.DataLoader(test_set, batch_size= 1000)\n\ntrain_batch= next(iter(train_loader))\nimages, labels= train_batch\npreds= network(images)\ntrain_loss= func.cross_entropy(preds, labels)\n\ntest_batch= next(iter(test_loader))\nimages, labels= test_batch\npreds= network(images)\ntest_loss= func.cross_entropy(preds, labels)\n\noptimizer= optim.Adam(network.parameters(), lr= 0.01)\n\nprint('train_loss:', train_loss.item())\nprint('test_loss:', test_loss.item())"},{"cell_type":"code","execution_count":39,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":"training on epoch: 1 and batch: 1, train loss: 2.31, test loss: 13.34\ntraining on epoch: 1 and batch: 2, train loss: 14.34, test loss: 6.23\ntraining on epoch: 1 and batch: 3, train loss: 6.84, test loss: 3.68\ntraining on epoch: 1 and batch: 4, train loss: 3.76, test loss: 2.56\ntraining on epoch: 1 and batch: 5, train loss: 2.57, test loss: 2.31\ntraining on epoch: 1 and batch: 6, train loss: 2.35, test loss: 2.31\ntraining on epoch: 1 and batch: 7, train loss: 2.33, test loss: 2.31\ntraining on epoch: 1 and batch: 8, train loss: 2.26, test loss: 2.32\ntraining on epoch: 1 and batch: 9, train loss: 2.34, test loss: 2.32\ntraining on epoch: 1 and batch: 10, train loss: 2.28, test loss: 2.29\ntraining on epoch: 1 and batch: 11, train loss: 2.32, test loss: 2.32\ntraining on epoch: 1 and batch: 12, train loss: 2.28, test loss: 2.20\ntraining on epoch: 1 and batch: 13, train loss: 2.23, test loss: 2.23\ntraining on epoch: 1 and batch: 14, train loss: 2.22, test loss: 2.21\ntraining on epoch: 1 and batch: 15, train loss: 2.21, test loss: 2.19\ntraining on epoch: 1 and batch: 16, train loss: 2.27, test loss: 2.15\ntraining on epoch: 1 and batch: 17, train loss: 2.09, test loss: 2.07\ntraining on epoch: 1 and batch: 18, train loss: 2.06, test loss: 2.08\ntraining on epoch: 1 and batch: 19, train loss: 2.32, test loss: 1.94\ntraining on epoch: 1 and batch: 20, train loss: 1.89, test loss: 1.96\ntraining on epoch: 1 and batch: 21, train loss: 1.98, test loss: 1.92\ntraining on epoch: 1 and batch: 22, train loss: 1.95, test loss: 1.82\ntraining on epoch: 1 and batch: 23, train loss: 1.71, test loss: 1.85\ntraining on epoch: 1 and batch: 24, train loss: 1.86, test loss: 1.77\n"},{"ename":"KeyboardInterrupt","evalue":"","output_type":"error","traceback":["\u001b[1;31m---------------------------------------------------------------------------\u001b[0m","\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[1;32m<ipython-input-39-ab44e698bafe>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     32\u001b[0m         \u001b[0mpreds\u001b[0m\u001b[1;33m=\u001b[0m \u001b[0mnetwork\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimages\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     33\u001b[0m         \u001b[0mtest_loss\u001b[0m\u001b[1;33m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcross_entropy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpreds\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 34\u001b[1;33m         \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'training on epoch: {} and batch: {}, train loss: {:.2f}, test loss: {:.2f}'\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mepoch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mi\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrain_loss\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtest_loss\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     35\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n","\u001b[1;31mKeyboardInterrupt\u001b[0m: "]}],"source":"# train test epochs\ndevice= torch.device('cuda')\nnetwork= Network()\ntrain_loader= torch.utils.data.DataLoader(train_set, batch_size= 100)\ntest_loader= torch.utils.data.DataLoader(test_set, batch_size= 10000)\noptimizer= optim.Adam(network.parameters(), lr= 0.1)\ntest_batch= next(iter(test_loader))\n\n# gpu specific\nnetwork.cuda()\n\nepochs= 10\nfor epoch in range(1, epochs):\n    i= 0\n    for batch in train_loader:\n        i+=1\n        images, labels= batch\n        # .to(cuda) for GPU\n        images= images.to('cuda')\n        labels= labels.to('cuda')\n        preds= network(images)\n        train_loss= func.cross_entropy(preds, labels)\n\n        optimizer.zero_grad()\n        train_loss.backward(retain_graph=True)\n        optimizer.step()\n        \n        images, labels= test_batch\n        # .to(cuda) for GPU\n        images= images.to('cuda')\n        labels= labels.to('cuda')\n        preds= network(images)\n        test_loss= func.cross_entropy(preds, labels)\n        print('training on epoch: {} and batch: {}, train loss: {:.2f}, test loss: {:.2f}'.format(epoch, i, train_loss.item(), test_loss.item()))\n\n"},{"cell_type":"code","execution_count":38,"metadata":{},"outputs":[{"ename":"RuntimeError","evalue":"CUDA error: out of memory","output_type":"error","traceback":["\u001b[1;31m---------------------------------------------------------------------------\u001b[0m","\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)","\u001b[1;32m<ipython-input-38-e5c6984d7ef4>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[0mimages\u001b[0m\u001b[1;33m=\u001b[0m \u001b[0mimages\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'cuda'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[0mlabels\u001b[0m\u001b[1;33m=\u001b[0m \u001b[0mlabels\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'cuda'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 8\u001b[1;33m \u001b[0mpreds\u001b[0m\u001b[1;33m=\u001b[0m \u001b[0mnetwork\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimages\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      9\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'correctly classified from 10000 images:'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mget_num_correct\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpreds\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n","\u001b[1;32m~\\Anaconda3\\envs\\pytorch-cuda\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m    475\u001b[0m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    476\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 477\u001b[1;33m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    478\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    479\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n","\u001b[1;32m<ipython-input-4-4ffb3f832d99>\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, t)\u001b[0m\n\u001b[0;32m     38\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mt\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     39\u001b[0m         \u001b[0mt\u001b[0m\u001b[1;33m=\u001b[0m \u001b[0mt\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 40\u001b[1;33m         \u001b[0mt\u001b[0m\u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconv1\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mt\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     41\u001b[0m         \u001b[0mt\u001b[0m\u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconv2\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mt\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     42\u001b[0m         \u001b[0mt\u001b[0m\u001b[1;33m=\u001b[0m \u001b[0mt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m12\u001b[0m\u001b[1;33m*\u001b[0m\u001b[1;36m4\u001b[0m\u001b[1;33m*\u001b[0m\u001b[1;36m4\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n","\u001b[1;32m~\\Anaconda3\\envs\\pytorch-cuda\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m    475\u001b[0m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    476\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 477\u001b[1;33m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    478\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    479\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n","\u001b[1;32m~\\Anaconda3\\envs\\pytorch-cuda\\lib\\site-packages\\torch\\nn\\modules\\container.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m     89\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     90\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_modules\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 91\u001b[1;33m             \u001b[0minput\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodule\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     92\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     93\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n","\u001b[1;32m~\\Anaconda3\\envs\\pytorch-cuda\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m    475\u001b[0m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    476\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 477\u001b[1;33m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    478\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    479\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n","\u001b[1;32m~\\Anaconda3\\envs\\pytorch-cuda\\lib\\site-packages\\torch\\nn\\modules\\conv.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m    299\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    300\u001b[0m         return F.conv2d(input, self.weight, self.bias, self.stride,\n\u001b[1;32m--> 301\u001b[1;33m                         self.padding, self.dilation, self.groups)\n\u001b[0m\u001b[0;32m    302\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    303\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n","\u001b[1;31mRuntimeError\u001b[0m: CUDA error: out of memory"]}],"source":"# final testing:\ndef get_num_correct(preds, labels):\n    return torch.argmax(preds, dim= 1).eq(labels).sum()\ntest_loader= torch.utils.data.DataLoader(test_set, batch_size= 1)\nimages, labels= test_batch\nimages= images.to('cuda')\nlabels= labels.to('cuda')\npreds= network(images)\nprint('correctly classified from 10000 images:', get_num_correct(preds, labels).item())"},{"cell_type":"code","execution_count":13,"metadata":{},"outputs":[{"ename":"OSError","evalue":"[Errno 22] Invalid argument: 'model/'","output_type":"error","traceback":["\u001b[1;31m---------------------------------------------------------------------------\u001b[0m","\u001b[1;31mOSError\u001b[0m                                   Traceback (most recent call last)","\u001b[1;32m<ipython-input-13-cc66aa45e43c>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# saving the torch model\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[0mPATH\u001b[0m\u001b[1;33m=\u001b[0m \u001b[1;34m'model/'\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msave\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnetwork\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstate_dict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mPATH\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[1;32m~\\Anaconda3\\envs\\pytorch-cuda\\lib\\site-packages\\torch\\serialization.py\u001b[0m in \u001b[0;36msave\u001b[1;34m(obj, f, pickle_module, pickle_protocol)\u001b[0m\n\u001b[0;32m    207\u001b[0m         \u001b[1;33m>>\u001b[0m\u001b[1;33m>\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msave\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbuffer\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    208\u001b[0m     \"\"\"\n\u001b[1;32m--> 209\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0m_with_file_like\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"wb\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mlambda\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0m_save\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpickle_module\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpickle_protocol\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    210\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    211\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n","\u001b[1;32m~\\Anaconda3\\envs\\pytorch-cuda\\lib\\site-packages\\torch\\serialization.py\u001b[0m in \u001b[0;36m_with_file_like\u001b[1;34m(f, mode, body)\u001b[0m\n\u001b[0;32m    130\u001b[0m             \u001b[1;33m(\u001b[0m\u001b[0msys\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mversion_info\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m3\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpathlib\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mPath\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    131\u001b[0m         \u001b[0mnew_fd\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 132\u001b[1;33m         \u001b[0mf\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    133\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    134\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mbody\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mf\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n","\u001b[1;31mOSError\u001b[0m: [Errno 22] Invalid argument: 'model/'"]}],"source":"# saving the torch model\nPATH= 'model'\ntorch.save(network.state_dict(), PATH)"},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":"# plotting the confusion matrix:\n"},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":""},{"cell_type":"code","execution_count":0,"metadata":{},"outputs":[],"source":"# Summary\nfrom torch import optim\n\n# train dataset download\ntrain_set= torchvision.datasets.FashionMNIST(\n    root= './data/FashionMNIST',\n    train= True,\n    download= True,\n    transform= transforms.Compose([\n        transforms.ToTensor()\n    ])\n)\n\n# network instance\nnetwork= Network()\n\n# train dataset loader\ntrain_loader= torch.utils.data.DataLoader(train_set, batch_size= 10)\n\n# optimizer function\noptimizer= optim.Adam(network.parameters(), lr=0.01)\n\n# load the first batch and iterate there after\nbatch = next(iter(data_loader))\nimages, labels= batch\n\n# prediction before anything\npreds= network(images)\nprint('previous prediction', accuracy(preds, labels))\n\n# initialize the loss function\nloss= nn.functional.cross_entropy(preds, labels)\nprint('previous loss:', loss.item())\n\n# initialize backward propagation\nloss.backward() # calculate gradients\noptimizer.step() # update weights\n\n# prediction after updating weights\npreds= network(images)\nloss= nn.functional.cross_entropy(preds, labels)\nprint('new loss:', loss.item())\nprint('new prediction:', accuracy(preds, labels))\n"}],"nbformat":4,"nbformat_minor":2,"metadata":{"language_info":{"name":"python","codemirror_mode":{"name":"ipython","version":3}},"orig_nbformat":2,"file_extension":".py","mimetype":"text/x-python","name":"python","npconvert_exporter":"python","pygments_lexer":"ipython3","version":3}}